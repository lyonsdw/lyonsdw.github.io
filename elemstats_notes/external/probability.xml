<section xml:id="probability_section"  xmlns:xi="http://www.w3.org/2001/XInclude">
<title>
Probability
</title>

<introduction>This section is coordinated with Freedman, <em>Statistics</em>
  <xref ref="freedman_statistics"/>, Chapters 13<ndash/>15.
</introduction>

<subsection>
  <title>Box Models</title>

  <p>
    A <term>box model</term><idx><h>box model</h>
    </idx>
    consists of a box that contains tickets, each of which is
equally likely to be selected on any single random draw from the box, as
in a fair lottery or raffle. In this course, every chance process can be
modeled in terms of a sequence of one or more random draws from a box
of tickets. The sequence of draws can be conducted in two different ways:
    <term>with replacement</term><idx><h>with replacement</h>
    </idx>
    or <term>without replacement</term><idx><h>without replacement</h>
    </idx>. These terms refer to whether or
not each ticket drawn from the box is replaced in the box before the
next draw; either way, it is assumed that on any given draw, every
ticket in the box at that moment has an equal chance to be selected.
</p>

  <p>The <term>outcome</term><idx><h>outcome</h>
    </idx>
    of a sequence of random draws is the list of specific
tickets that were drawn. That is, an outcome is a list of the form
    <me>  \text{(1st ticket drawn), (2nd ticket drawn), ... , (last ticket drawn)}.</me>
The assumption that each ticket is equally likely to be selected on any
given random draw implies that every draw sequence outcome is equally
    likely. A set of outcomes is called
    an <term>event</term><idx><h>event</h></idx>. We say an
    event <term>happens</term><idx><h>happens</h>
    </idx>
    or
    <term>occurs</term><idx><h>occurs</h>
    </idx>
    if a sequence of random draws produces an outcome that belongs to
    that event. The <term>probability</term><idx><h>probability (that an
	event occurs)</h></idx>
    that an event occurs is the fraction
    <me> \frac{\text{number of outcomes in the event}}{\text{total number of possible outcomes}}.</me>
    We usually use capital letters to denote events. We
    write <m>P(A)</m>
    to
    denote the probability of an event <m>A</m>. Here is the basic definition of
probability using these symbols.
    <men xml:id="eventprobdef">
      P(A) = \frac{\text{number of outcomes in } A}{\text{total number of  possible outcomes}}</men>
  </p>
  
  <example xml:id="probeg1">
    <p>
      Consider the box with tickets labeled <m>x,y,z</m>
    and consider the
chance process that selects two tickets, without replacement, from the
box. The set of all possible outcomes is
    <me>  \{(x,y), (x,z), (y,x), (y,z), (z,x), (z,y)\}</me>
    where the pair <m>(y,x)</m>, for example, denotes the outcome
    where <m>y</m>
    is
    selected on the first draw, and <m>x</m>
    is selected on the second draw. The
    event <m>A = \text{ "get an } x \text{"}</m>
    is the set
    <me>  A=\{(x,y), (x,z), (z,x), (y,x)\}</me>
    and the event <m>B = \text{ "get an } x \text{ on draw 1"}</m>
    is the set
    <me>B=\{(x,y), (x,z)\}.</me>
We have the following probabilities.
    <md>
      <mrow>P(A) \amp = P(\text{get an } x) = 4/6 = 2/3</mrow>
      <mrow>P(B) \amp = P(\text{get an } x \text{ on draw 1}) = 2/6 = 1/3</mrow>
    </md></p>
  </example>


<p>The point of the rest of this section is that we want to avoid having to
explicitly list and count outcomes in order to calculate probabilities;
we want to use shortcuts instead. First, we need more vocabulary.
</p>
</subsection>

<subsection>
  <title>Complement, Intersection, Union of Events</title>

  <p>The <term>opposite</term><idx><h>opposite of an event</h>
    </idx>
    of an event <m>U</m>
    (also called the <term>complement</term><idx><h>complement</h>
    </idx>
    of <m>U</m>) is the
    event that consists of all the outcomes not in <m>U</m>. For two
    events <m>U,V</m>,
    the event <m>\text{"}U \AND V\text{"}</m> (also called
    the <term>intersection</term><idx><h>intersection of events</h>
    </idx>
    of <m>U</m>
    and <m>V</m>) is the set
    of all the outcomes shared by both <m>U</m>
    and <m>V</m>. The event <m>\text{"}U \OR V\text{"}</m> (also
    called the <term>union</term><idx><h>union of events</h>
    </idx>
    of <m>U</m>
    and <m>V</m>) is the set of all the outcomes that are in <m>U</m>
    or in <m>V</m>
    or both. Events <m>U,V</m>
    are called <term>mutually exclusive</term>
    if the event <m>\text{"}U \AND V\text{"}</m> is empty.
</p>

  <example xml:id="probeg2"><p>Continuing <xref ref="probeg1"/>, consider these events.
  <md>
    <mrow>C \amp = \text{ "get an } x \text{ on draw 2" } = \{(y,x), (z,x)\}</mrow>
    <mrow>D \amp = \text{"get a }y \text{" } = \{(x,y), (z,y), (y,x), (y,z)\}</mrow>
</md>
The we have the following.
  <md>
    <mrow>\text{opposite of } A \amp = \{(y,z), (z,y)\}</mrow>
    <mrow>A \AND D \amp= \{(x,y), (y,x)\}</mrow>
    <mrow>C \OR D \amp = \{(x,y), (z,y), (y,x), (y,z), (z,x)\}</mrow>
</md>
  The event <m>B \AND C</m>
  is the empty set, so <m>B,C</m>
  are mutually exclusive.</p>
  </example>
</subsection>

<subsection>
  <title>Conditional Probability</title>

<p>Suppose we are about to make a sequence of draws from a box model and we
are considering the probability that the outcome will be in some event
  <m>V</m>. Using definition <xref ref="eventprobdef"/>, we have this.
  <men xml:id="condprobdisc2">P(V) = \frac{\text{number of outcomes in }
    V}{\text{total number of possible outcomes}}</men> Suppose now that
    we are somehow guaranteed that the outcome of our draws will be in a
    particular event <m>U</m>, and that all of the outcomes in <m>U</m>
    are equally likely. This effectively reduces the pool of possible
    outcomes: any outcome that is not in <m>U</m> should not be
    considered in the top or the bottom of the fraction on the right
    side of <xref ref="condprobdisc2"/>. We define the <term>conditional
    probability of V given U</term><idx><h>conditional
      probability</h> </idx>,
  denoted <m>P(V|U)</m><notation><usage><m>P(V|U)</m></usage><description>conditional
      probability of <m>V</m> given <m>U</m></description></notation>, to be
  <men xml:id="condprobintuition">P(V|U) = \frac{\text{number of outcomes in } U
  \AND V}{\text{number of outcomes in } U}.</men>
  The conditional probability <m>P(V|U)</m>
  reflects our updated assessment of
  the likelihood that the outcome of our sequence of draws will be
  in <m>V</m>,
  in the presence of the knowledge that the outcome is in <m>U</m>. Dividing the
top and bottom of the fraction on the right side of <xref ref="condprobintuition"/> by the total number of possible
outcomes yields the following expression for conditional probability.
  <men xml:id="condprobdef">P(V|U) = \frac{P(U \AND V)}{P(U)}</men>
</p>

<example>Continuing <xref ref="probeg1"/> and <xref ref="probeg2"/>, we have the following.
  <md>
    <mrow>P(A|B) \amp = 1</mrow>
    <mrow>P(B|C) \amp = 0</mrow>
    <mrow>P(B|A) \amp = 1/2</mrow>
    <mrow>P(A|D) \amp = 1/2</mrow>
</md>
</example>

</subsection>

<subsection><title>Independent and Dependent Events</title>

  <p>If <m>P(V) = P(V|U)</m>, the events <m>U,V</m>
    are called <term>independent</term><idx><h>independent events</h>
    </idx>. Otherwise, the
    events are called <term>dependent</term><idx><h>dependent events</h></idx>. Using the word "independent" to describe
    events <m>U,V</m>
    reflects the fact that knowing whether or not an outcome is
    guaranteed to be in event <m>U</m>
    does not affect the way we assess the
    probability of event <m>V</m>.
</p>
</subsection>

<subsection>
  <title>Probability Rules</title>

<p>The usefulness of the following equations is when something you want to
know can be put in the form of the expressions on the left sides, and
the expressions on the right sides are easier to compute. Most of the
time, these rules save you from having to make explicit lists and counts
of outcomes.
</p>

<p>Rearranging <xref ref="condprobdef"/>, we have the following equation, called the
  <term>multiplication rule</term><idx><h>multiplication rule</h></idx>.
  <me>  P(U \AND V) = P(U) \cdot P(V|U)</me>
  If <m>U,V</m>
  are independent, the multiplication rule simplifies a little.
  <me>  P(U \AND V) = P(U) \cdot P(V)    \;\;\;(U,V \text{ independent})</me>
  If <m>U,V</m>
  are mutually exclusive, we have the following equation, called
  the <term>addition rule for mutually exclusive
    events</term><idx><h>addition rule (for mutually exclusive events)</h></idx>.
  <me>  P(U \OR V) = P(U) + P(V)   \;\;\;(U,V \text{ mutually exclusive})</me>
  A special case of the addition rule is when <m>V</m>
  is the opposite of <m>U</m>. In
  this case, <m>U \OR V</m> is the set of all possible outcomes, so
  <m>P(U \OR V) = 1</m>. Rearranging the addition rule terms, we have
  the <term>opposite rule</term><idx><h>opposite rule</h></idx> .
  <me>P(U) = 1 - P(\text{ opposite of } U)</me>
</p>
</subsection>

<subsection>
  <title>The Binomial Formula</title>

<p>Consider a box model in which the tickets are divided into two
  categories: <m>W</m>
  (for winning tickets) and <m>L</m>
  for (losing tickets). Let <m>p</m>
  be
the probability that a single random draw is a winning ticket. In
symbols we have the following.
  <md>
    <mrow>P(W) \amp = p</mrow>
    <mrow>P(L) \amp = 1 - p</mrow>
</md>
</p>

<p>
Now consider a sequence of random draws, with replacement. Let <m>n</m>
be the
number of draws in the sequence (<m>n</m>
is some positive whole number), and
let <m>S</m>
be the event
<me>  S = \text{"get exactly } k \;\;W's \text{ and } (n-k)\;\; L\text{'s in } n
  \text{ draws"}</me>
where <m>k</m>
is some whole number in the range from 0 to <m>n</m>. For example, the
outcome <m>WLWWL</m>
belongs to <m>S</m>
for <m>n=5</m>
and <m>k=3</m>. The binomial formula is
<me>  P(S) = {n \choose k}  p^k (1-p)^{n-k}</me>
where <m>{n \choose k}</m>
is the quantity
<me>  {n \choose k} = \frac{n!}{k! (n-k)!}.</me>
The number <m>{n \choose k}</m>, called a <term>binomial
  coefficient</term><idx><h>binomial coefficient</h></idx>, is the number of
different <m>n</m>-letter words you can write with <m>k</m>
<m>W</m>'s and <m>(n-k)</m>
<m>L</m>'s.
For example, the number of different 5-letter words you can write with
<m>k=3</m>
<m>W</m>'s and <m>n-k=2</m>
<m>L</m>'s is
<me>  {5 \choose 3} = \frac{5!}{3!2!} = 10.</me>
Indeed, here is the list of the 10 words.
<md><mrow>WWWLL, WWLWL, WLWWL, LWWWL, WWLLW, </mrow>
  <mrow>WLWLW, LWWLW, WLLWW, LWLWW, LLWWW</mrow>  
</md>
For the box with 1 <m>W</m>
and 3 <m>L</m>'s (so <m>p=P(W)=1/4</m>), the chance
of getting exactly <m>k=3</m>
<m>W</m>'s in <m>n=5</m>
draws is
<m>  {5 \choose 3}  (1/4)^3  (3/4)^2 \approx 8.79\%.</m>
</p>

<p>
Here is the reasoning for why the binomial formula works, in brief:
There are <m>n \choose k</m>
outcomes with <m>k</m>
<m>W</m>'s and <m>(n-k)</m>
<m>L</m>'s. All of these
  outcomes are mutually exclusive to one another, so the probability of
getting an outcome sequence with exactly <m>k</m>
<m>W</m>'s in in draws is the sum
  of the probabilities of each individual outcome (by the addition
rule). Any particular sequence of <m>k</m>
<m>W</m>'s and <m>(n-k)</m>
<m>L</m>'s has a probability
of <m>p^k (1-p)^{n-k}</m>
(by the multiplication rule for independent
events). Put all this together and you get the binomial formula.
</p>
</subsection>

</section>

